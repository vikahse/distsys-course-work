Метод on_local_message:

Когда к нам приходит запрос GET, я ищу номера реплик при помощи метода get_key_replicas, создаю для отправки им GET сообщение с key, id_owner(чтобы потом локально отправить), 
quorum(чтобы понимать достигнут ли кворум), timestamp(для реализации last write wins стратегии). Затем у меня есть словарь quorum_get, где по ключу я храню кол-во ответов, которые пришли от нод, чтобы
контролировать достижение кворума. Соответственно при обработке GET я инициализирую quorum_get[msg['key']] = 0 нулем. (Например, если 
такой ключ ранее был обработан, я не удаляю его из словаря, а инициализирую -1, чтобы не путать с началом обработки запроса). Затем я отправляю всем репликам данное сообщение и завожу таймер quorum_read для
данного ключа, чтобы реализовать sloppy quorum. 


Когда к нам приходит запрос PUT, я ищу номера реплик при помощи метода get_key_replicas, создаю для отправки им PUT сообщение с key, vslue, id_owner(чтобы потом локально отправить), 
quorum(чтобы понимать достигнут ли кворум), timestamp. Так же инициализирую нулем quorum_put[msg['key']] = 0 (идея этого словаря аналогична с тем, что и у quorum_get). 
И завожу таймер quorum_write для данного ключа, чтобы реализовать sloppy quorum.

Когда к нам приходит запрос DELETE, я ищу номера реплик при помощи метода get_key_replicas, создаю для отправки им DELETE сообщение с key, vslue, id_owner(чтобы потом локально отправить), 
quorum(чтобы понимать достигнут ли кворум), timestamp. Так же инициализирую нулем quorum_delete[msg['key']] = 0 (идея этого словаря аналогична с тем, что и у quorum_get). 

Метод on_message:

Когда к нам приходит запрос PUT, я проверяю хранится ли уже этот ключ у ноды, если нет, то кладу его в self._data и не забываю сохранить timestamp в словаре self._timestamp_key по ключу, 
иначе сравниваю имеющийся timestamp с переданным, если переданным timestamp больше, то перезаписываю все, иначе сравниваю в лексикографическом порядке значения. 
Затем формирую PUT_RESP сообшение с key, value, quorum, timestamp и отсылаю его id_owner.

Когда к нам приходит запрос GET, я достаю value из self._data и timestamp из self._timestamp_key, формирую GET_RESP сообщение (аналогично PUT_RESP) и отправляю id_owner.

Когда к нам приходит запрос DELETE, мы удаляем значение из self._data и обновляем self._timestamp_key (чтобы можно было сравнивать на временной шкале, что и какие действия с ключом происходили).
Затем составляем DELETE_RESP сообщение с key, value, quorum, timestamp, timestamp_del и отправляем его id_owner.

Когда к нам приходит запрос PUT_CHECK, мы сравниваем свое значение по переданному ключу в соотвествии с тем, как это делалось при обработке запроса PUT. И при необходимости завершаем таймер. 

Когда к нам приходит запрос CANCEL_TIMER_WRITE мы останавливаем соотвествующий таймер и обнуляем переменную safe_value.

Когда к нам приходит запрос PUT_RESP, если кворум еще не закрылся, то мы увеличиваем счетчик, сохраняем в текущую переменную put_value значение (переменная put_value нужна для запоминания пришедших ответов от нод, чтобы их можно было сравнивать и выбирать только те значения, у которых timestamp больше).
Если кворум был достигнут, мы локально уже отправляем PUT_RESP сообщение, а затем создаем PUT_CHECK сообщение с key, value, timestamp и отправляем его всем репликам, отвечающим за этот ключ, чтобы они могли сравнить и при необходимости обновить у себя значение ключа. 
Так же не забываем обнулять quorum_put[msg['key']] = -1 (говорит о конце обработки запроса), put_value = None.

Когда к нам приходит запрос GET_RESP/DELETE_RESP, то все обрабатывается аналогично запросу PUT_RESP.

Когда к нам приходит запрос PUT_RESERV/GET_RESERV, то мы обрабатываем случай запроса PUT, только для резервной ноды, когда кворму не был достигнут. Здесь сохранение значения аналогично с тем, как это описано в PUT запросе, 
затем я завожу таймер put_alive для всех реплик, для того, чтобы отправлять PUT_CHECK сообщение репликам, в тот момент, когда они восстановятся. 

Запрос PUT_RESP_RESERV/GET_RESP_RESERV аналогичен PUT_RESP/GET_RESP.

Метод on_timer:

put_alive: пингует сообщение с новыми значениями, когда не был достигнут кворум 

quorum_write/quorum_read: если кворум не был достигнут, то мы ищем резервную реплику и отправляем ей PUT_RESERV/GET_RESERV сообщение. Так же я обрабатываю случай, когда в put_value 
уже было сохранено значение, тогда я отправляю уже его, и не обращаюсь к резервной реплике. 

Задание: 
Описание любой ситуации, когда при кворумах W + R > N система может выдать не последнее успешно записанное значение (запись успешна, если клиент получил W ответов).

W = 1, R = 3, N = 3 (A, B, C)

Пусть приходит запрос PUT key valye на ноду А (пусть реплики key - A, B), она обрабатывает его, сохраняет значение, но ломается и не успевает реплицировать значение на оставшиеся реплики (например, сообщение о записи на ноду B было потеряно). Но при этом запрос на W считается успешным, так как кворум был достигнут. 
Затем приходит запрос на GET key на ноду С, она отправляет запросы на A, B, но так как нода А все еще отключена, кворум не достигнут, тогда мы обращаемся к резервной ноде С, которая сравнивает свое значение, например, с ответом от ноды B и отправляет ответ клиенту, при этом у этих обоих нод будет устаревшее значение, и в итоге система отправит его.







